{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb5679b7-dd7b-4cff-818f-d3ad9f940acc",
   "metadata": {},
   "source": [
    "Building a Regression Models with Keras\n",
    "\n",
    "This project can be broken down into 4 parts:\n",
    "A. Build a baseline model and run it\n",
    "B. Normalize the data and re-run the model \n",
    "C. Increase the number of epochs from 50 to 100\n",
    "D. Increase the number of hidden layers from 1 to 3\n",
    "\n",
    "The intent is to identify how the mean of the mean squared errors changes with each of the above parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f80c441-a5ac-4336-a4a1-6bf22fab18e6",
   "metadata": {},
   "source": [
    "A. Build the baseline model\n",
    "\n",
    "First step is to include the libraries that are needed in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c6566a-a5fc-4f5a-8145-dc66d7bc9492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented. \n",
    "# If you run this notebook on a different environment, e.g. your desktop, you may need to uncomment and install certain libraries.\n",
    "\n",
    "#!pip install numpy==1.21.4\n",
    "#!pip install pandas==1.3.4\n",
    "#!pip install keras==2.1.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831b481-7613-4404-be35-ab19524ada6b",
   "metadata": {},
   "source": [
    "Import the various packages that are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18108666-8887-4cf3-8aea-48b8b2a733f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1b1445-96c9-4349-9ce0-433c656c296c",
   "metadata": {},
   "source": [
    "Load the dataset for the concrete that we will be processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee76a47-f871-4df7-9f15-8ba18ba07455",
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390cbe14",
   "metadata": {},
   "source": [
    "Verify that there are no missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4657c72c-0fbe-47e1-ae2f-5f0a298d095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(concrete_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0b15b7",
   "metadata": {},
   "source": [
    "Split the data into predictors and target, where 'Strength' is the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce00b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data_columns = concrete_data.columns\n",
    "\n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "target = concrete_data['Strength'] # Strength column\n",
    "n_cols = predictors.shape[1] # number of predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e9c659",
   "metadata": {},
   "source": [
    "Define the single node model, so that we can re-use this function for parts A, B and C.\n",
    "\n",
    "The number of predictor columns are passed into the function for future re-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73685ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regression_model\n",
    "def single_hidden_layer_model(n_cols):\n",
    "    model = Sequential()\n",
    "    input_shape = keras.Input(shape=(n_cols,))  # Returns a 'placeholder' tensor for Input shape\n",
    "    model.add(input_shape)  # Adds the input shape to the model\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')  # Configures the model for training\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3243d79",
   "metadata": {},
   "source": [
    "Here we start the core work of part A and repeat it 50 times to have a list of 50 MSE's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_list = []\n",
    "#\n",
    "for repetition in range(50):\n",
    "    #\n",
    "    print(\"Iteration : \", repetition + 1)\n",
    "    # split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=42)\n",
    "    # Build the model\n",
    "    model = single_hidden_layer_model(n_cols)           # create the model\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)   # fit the model with 50 epochs\n",
    "    # evaluate using mean squared error\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list.append(mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6e3f34",
   "metadata": {},
   "source": [
    "Upon completion calculate the mean of the MSE's and the standard deviation and print the results; we have completed part A at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd17ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "print(\"\\nMean squared error: \", np.mean(mse_list))\n",
    "print(\"Standard deviation: \", np.std(mse_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6471658",
   "metadata": {},
   "source": [
    "B. Normalize the data and repeat A\n",
    "\n",
    "First step is to normalize the data by subtracting the mean and dividing by the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4e636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data by substracting the mean and dividing by the standard deviation\n",
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "print(\"\\nNormalized predictors head:\\n\", predictors_norm.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0f15c",
   "metadata": {},
   "source": [
    "Next we start the core work of part B and repeat it 50 times to have a list of 50 MSE's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c289c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_mse_list = []\n",
    "#\n",
    "for repetition in range(50):\n",
    "    #\n",
    "    print(\"Iteration : \", repetition + 1)\n",
    "    # split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=42)\n",
    "    # Build the model\n",
    "    model = single_hidden_layer_model(n_cols)\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)   # 50 epochs\n",
    "    # evaluate using mean squared error\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    norm_mse_list.append(mse)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7a1d1f",
   "metadata": {},
   "source": [
    "We've completed the work for part B, so let's take a look at the mean of MSE's and the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea338475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "print(\"\\nNormalized Mean squared error: \", np.mean(norm_mse_list))\n",
    "print(\"Normalized Standard deviation: \", np.std(norm_mse_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc15baeb",
   "metadata": {},
   "source": [
    "C. Repeat part B, but this time with 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1515ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "cent_mse_list = []\n",
    "#\n",
    "for repetition in range(50):\n",
    "    #\n",
    "    print(\"Iteration : \", repetition + 1)\n",
    "    # split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=42)\n",
    "    # Build the model\n",
    "    model = single_hidden_layer_model(n_cols)\n",
    "    model.fit(X_train, y_train, epochs=100, verbose=0)  # 100 epochs\n",
    "    # evaluate using mean squared error\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    cent_mse_list.append(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5af9cd9",
   "metadata": {},
   "source": [
    "We've completed the run for part C, so print the results for mean MSE's and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "print(\"\\n100-epoch Mean squared error: \", np.mean(cent_mse_list))\n",
    "print(\"100-epoch Normalized Standard deviation: \", np.std(cent_mse_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e145aec0",
   "metadata": {},
   "source": [
    "D. Repeat of part C, but now with a model using 3 hidden layers.\n",
    "\n",
    "Define the function for three hidden layers first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49380e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_hidden_layer_model(n_cols):\n",
    "    model = Sequential()\n",
    "    input_shape = keras.Input(shape=(n_cols,))  # Returns a 'placeholder' tensor for Input shape\n",
    "    model.add(input_shape)                      # Adds the input shape to the model\n",
    "    model.add(Dense(10, activation='relu'))     # Add three hidden layers with 10 nodes each\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cedc36f",
   "metadata": {},
   "source": [
    "Run with 100 epochs, as in part C, but now with the 3 hidden layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9acb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_cent_mse_list = []\n",
    "#\n",
    "for repetition in range(50):\n",
    "    #\n",
    "    print(\"Iteration : \", repetition + 1)\n",
    "    # split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3, random_state=42)\n",
    "    # Build the model\n",
    "    model = three_hidden_layer_model(n_cols)\n",
    "    model.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "    # evaluate using mean squared error\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    three_cent_mse_list.append(mse)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9df47f",
   "metadata": {},
   "source": [
    "Ran the model to completion, so let's take a look at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c8055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "print(\"\\nThree-hidden-layer 100-epoch Mean squared error: \", np.mean(three_cent_mse_list))\n",
    "print(\"Three-hidden-layer 100-epoch Normalized Standard deviation: \", np.std(three_cent_mse_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad753f9b",
   "metadata": {},
   "source": [
    "All work is now complete. We see that the model gets better with each part:\n",
    "- Part B's normalization of the predictors improves the standard deviation significantly over part A\n",
    "- Part C's use of 100 epochs over 50, reduces both MSE and StdDev\n",
    "- Part D's addition of 2 more hidden layers makes for a significantly better MSE and similar StdDev\n",
    "\n",
    "For quick comparison, here are all the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520031e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "print(\"\\nMean squared error: \", np.mean(mse_list))\n",
    "print(\"Standard deviation: \", np.std(mse_list))\n",
    "#\n",
    "print(\"\\nNormalized Mean squared error: \", np.mean(norm_mse_list))\n",
    "print(\"Normalized Standard deviation: \", np.std(norm_mse_list))\n",
    "#\n",
    "print(\"\\n100-epoch Mean squared error: \", np.mean(cent_mse_list))\n",
    "print(\"100-epoch Normalized Standard deviation: \", np.std(cent_mse_list))\n",
    "#\n",
    "print(\"\\nThree-hidden-layer 100-epoch Mean squared error: \", np.mean(three_cent_mse_list))\n",
    "print(\"Three-hidden-layer 100-epoch Normalized Standard deviation: \", np.std(three_cent_mse_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06742c79-8347-4e45-87f1-005b5ddb6e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
